{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "This notebook explores hyperparameter tuning. It uses the boston house price dataset built into Sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Sklearn processing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Sklearn regression algorithms\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Sklearn regression model evaluation functions\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data, split into X and y and scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load built-in sample data set\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "# Define the X (input) and y (target) features\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# Rescale the input features\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(boston.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty model\n",
    "model = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "          weights='uniform')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the model's default hyperparameters:\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What hyperparameters can we tune?\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyperparameters with grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7711643653097031\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "          weights='distance')\n",
      "{'n_neighbors': 3, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "algorithm = KNeighborsRegressor()\n",
    "\n",
    "# Create 3 folds\n",
    "seed = 13\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "\n",
    "# Define our candidate hyperparameters\n",
    "hp_candidates = [{'n_neighbors': [2,3,4,5,6], 'weights': ['uniform','distance']}]\n",
    "\n",
    "# Search for best hyperparameters\n",
    "grid = GridSearchCV(estimator=algorithm, param_grid=hp_candidates, cv=kfold, scoring='r2')\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Get the results\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a full breakdown of the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\llewe\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\llewe\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\llewe\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\llewe\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\llewe\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00068895, 0.0006659 , 0.00066487, 0.        , 0.00033291,\n",
       "        0.00033267, 0.        , 0.00033021, 0.        , 0.00066503]),\n",
       " 'std_fit_time': array([0.00048801, 0.00047086, 0.00047013, 0.        , 0.00047081,\n",
       "        0.00047047, 0.        , 0.00046699, 0.        , 0.00047025]),\n",
       " 'mean_score_time': array([0.00165955, 0.00132926, 0.00099691, 0.00166241, 0.00165264,\n",
       "        0.00099738, 0.0013322 , 0.00200272, 0.00165311, 0.00133212]),\n",
       " 'std_score_time': array([6.26565729e-04, 4.70134207e-04, 2.24783192e-07, 4.70471865e-04,\n",
       "        9.28298393e-04, 5.94720425e-07, 4.68565457e-04, 1.26474259e-05,\n",
       "        4.63703822e-04, 4.71821366e-04]),\n",
       " 'param_n_neighbors': masked_array(data=[2, 2, 3, 3, 4, 4, 5, 5, 6, 6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_weights': masked_array(data=['uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_neighbors': 2, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 2, 'weights': 'distance'},\n",
       "  {'n_neighbors': 3, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 3, 'weights': 'distance'},\n",
       "  {'n_neighbors': 4, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 4, 'weights': 'distance'},\n",
       "  {'n_neighbors': 5, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 5, 'weights': 'distance'},\n",
       "  {'n_neighbors': 6, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 6, 'weights': 'distance'}],\n",
       " 'split0_test_score': array([0.75746893, 0.77908312, 0.70347418, 0.76215602, 0.6694333 ,\n",
       "        0.74843647, 0.69081694, 0.75488853, 0.6856312 , 0.75527275]),\n",
       " 'split1_test_score': array([0.7563289 , 0.77658452, 0.74134188, 0.77490906, 0.70229635,\n",
       "        0.75883128, 0.69261149, 0.74883153, 0.68249855, 0.73851307]),\n",
       " 'split2_test_score': array([0.74306357, 0.75452132, 0.74565457, 0.77645934, 0.73099167,\n",
       "        0.77635982, 0.7114727 , 0.76799139, 0.68645688, 0.75685882]),\n",
       " 'mean_test_score': array([0.75230536, 0.7700937 , 0.73012625, 0.77116437, 0.70084765,\n",
       "        0.76117925, 0.69827435, 0.7572159 , 0.68485906, 0.75020175]),\n",
       " 'std_test_score': array([0.0065322 , 0.01102609, 0.01895566, 0.00641059, 0.02513951,\n",
       "        0.01151466, 0.00933385, 0.00798991, 0.00170522, 0.00830266]),\n",
       " 'rank_test_score': array([ 5,  2,  7,  1,  8,  3,  9,  4, 10,  6]),\n",
       " 'split0_train_score': array([0.92014175, 1.        , 0.87569225, 1.        , 0.83242189,\n",
       "        1.        , 0.81936047, 1.        , 0.78948797, 1.        ]),\n",
       " 'split1_train_score': array([0.92483171, 1.        , 0.87445713, 1.        , 0.83614246,\n",
       "        1.        , 0.81985446, 1.        , 0.79273034, 1.        ]),\n",
       " 'split2_train_score': array([0.92585254, 1.        , 0.87843873, 1.        , 0.8362253 ,\n",
       "        1.        , 0.79360269, 1.        , 0.74016475, 1.        ]),\n",
       " 'mean_train_score': array([0.92360867, 1.        , 0.87619604, 1.        , 0.83492988,\n",
       "        1.        , 0.81093921, 1.        , 0.77412769, 1.        ]),\n",
       " 'std_train_score': array([0.00248665, 0.        , 0.00166406, 0.        , 0.00177374,\n",
       "        0.        , 0.01226043, 0.        , 0.02405187, 0.        ])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prove that best_score_ is the mean of all the k-fold scores\n",
    "Here's a little check to see how best_score_ is derived from cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the index of the best hyperparameter combination chosen by GridSearchCv()\n",
    "grid.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7711643653097031\n",
      "0.006410593055068143\n"
     ]
    }
   ],
   "source": [
    "# Get the mean and std of the k-fold scores for the best hyperparameter combination\n",
    "print(grid.cv_results_['mean_test_score'][grid.best_index_])\n",
    "print(grid.cv_results_['std_test_score'][grid.best_index_])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
